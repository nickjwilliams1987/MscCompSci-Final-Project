{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footfall data exploration\n",
    "\n",
    "The Leeds city centre footfall data provided by Data Mill North is, quite simply, a mess. While files are consistently provided in a csv format, they have changed several times over the years with column names being added, removed and changed, date formats changing etc.\n",
    "\n",
    "This notebook explores the data to develop a methodology to clean the data up and provide a single, consistent view of it.\n",
    "\n",
    "https://datamillnorth.org/dataset/leeds-city-centre-footfall-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The objective of this file is to provide a single, consistent table with the following fields:\n",
    "* Location\n",
    "* Timestamp (date and hour)\n",
    "* Total footfall\n",
    "\n",
    "This will enable us to build a historic view of footfall figures based on the files that already exist, and build a data pipeline which recognises the data format of any new files so they can be loaded to the DW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve files\n",
    "Retrieve all files and save them to the files directory, ready for processing.\n",
    "\n",
    "NOTE: At the time of writing, this step downloads 214 seperate files, totalling 72mb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded headrow.csv\n",
      "Downloaded Monthly Data Feed - Dec 2017.csv\n",
      "Downloaded briggate-at-mcdonalds.csv\n",
      "Downloaded Monthy Data Feed - June 2017.csv\n",
      "Downloaded Copy of Monthly Data Feed-June 2016.csv\n",
      "Downloaded Monthly Data Feed-April 2017 - 20170510.csv\n",
      "Downloaded Monthly Data Feed -  Jan 2018.csv\n",
      "Downloaded Copy of Monthly Data Feed-December 2015 - 20160106.csv\n",
      "Downloaded monthly-data-feed-oct-2014-20141107.csv\n",
      "Downloaded Monthly Data Feed-May 2015 - 20150601 (1).csv\n",
      "Downloaded Monthly Data Feed-Apr 2016 - 20160501.csv\n",
      "Downloaded Copy of Monthly Data Feed-May 2016 - 20160531.csv\n",
      "Downloaded Monthly Data Feed - April 2018.csv\n",
      "Downloaded monthly-data-feed-june-2014-20140710.csv\n",
      "Downloaded Copy of Monthly Data Feed-March 2017 - 20170403.csv\n",
      "Downloaded Monthly Data Feed-October 2015 - 20151203.csv\n",
      "Downloaded albion-street-south.csv\n",
      "Downloaded Copy of Monthly Data Feed-December 2016 - 20170208.csv\n",
      "Downloaded dortmund-square.csv\n",
      "Downloaded Monthly Data Feed-September 2016 - 20161102.csv\n",
      "Downloaded Monthly Data Feed-August 2015 - 20150917.csv\n",
      "Downloaded copy-of-monthly-data-feed-feb-2015-20150306.csv\n",
      "Downloaded Copy of Monthly Data Feed - Sept 2017.csv\n",
      "Downloaded Copy of Monthly Data Feed-November 2016 - 20161221.csv\n",
      "Downloaded Monthly Data Feed-November 2015 - 20151203.csv\n",
      "Downloaded monthly-data-feed-aug-2014-20140904.csv\n",
      "Downloaded monthly-data-feed-sept-2014-20141009.csv\n",
      "Downloaded briggate.csv\n",
      "Downloaded Monthly Data Feed-April 2015 - 20150507.csv\n",
      "Downloaded Monthly Data Feed - July 2017.csv\n",
      "Downloaded copy-of-monthly-data-feed-march-2015-20150410.csv\n",
      "Downloaded Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv\n",
      "Downloaded Monthly Data Feed-September 2015 - 20151012.csv\n",
      "Downloaded commercial-street-at-barratts.csv\n",
      "Downloaded Copy of Monthly Data Feed-July 2016 - 20160802.csv\n",
      "Downloaded Copy of Monthly Data Feed-January 2017 - 20170208.csv\n",
      "Downloaded Copy of Monthly Data Feed-Feb 2016 - 20160324.csv\n",
      "Downloaded Monthly Data Feed - May 2018.csv\n",
      "Downloaded Monthly Data Feed - June 2018.csv\n",
      "Downloaded Monthly Data Feed-October 2016 - 20161102.csv\n",
      "Downloaded monthly-data-feed-jan-2015-20150205.csv\n",
      "Downloaded monthly-data-feed-nov-2014-20141205.csv\n",
      "Downloaded Monthly Data Feed - Nov 2017.csv\n",
      "Downloaded Monthly Data Feed-March 2018.csv\n",
      "Downloaded Monthly Data Feed-July 2015 - 20150807.csv\n",
      "Downloaded Copy of Monthly Data Feed - Oct 2017.csv\n",
      "Downloaded Monthly Data Feed-Jan 2016 - 20160222.csv\n",
      "Downloaded Monthly Data Feed-Feb 2018.csv\n",
      "Downloaded footfall.csv\n",
      "Downloaded monthly-data-feed-dec-2014-20150108.csv\n",
      "Downloaded Copy of Monthly Data Feed-February 2017 - 20170301.csv\n",
      "Downloaded Monthly Data Feed - May 2017.csv\n",
      "Downloaded Monthly Data Feed -  August 2017.csv\n",
      "Downloaded commercial-street-at-lush.csv\n",
      "Downloaded Monthly Data Feed-June 2015 - 20150703 (4).csv\n",
      "Downloaded monthly-data-feed-july-2014-20140811.csv\n",
      "Downloaded albion-street-north.csv\n",
      "Downloaded Copy of Monthly Data Feed-Mar 2016 - 20160425.csv\n",
      "Downloaded Monthly Data Feed - July 2018.csv\n",
      "Downloaded Monthly Data Feed - August 2018.csv\n",
      "Downloaded Monthly Data Feed - Sept 2018.csv\n",
      "Downloaded 01.10.2018 - 31.10.2018.csv\n",
      "Downloaded Monthly Data feed - Nov 2018.csv\n",
      "Downloaded Monthly Data Feed - Dec 2018.csv\n",
      "Downloaded Monthly Data Feed - Jan 2019.csv\n",
      "Downloaded Monthly Data Feed - Feb 2019.csv\n",
      "Downloaded Monthly Data Feed - Mar 2019.csv\n",
      "Downloaded Copy of Monthly Data Feed-April 2019.csv\n",
      "Downloaded Copy of Monthly Data Feed-May 2019.csv\n",
      "Downloaded Copy of Monthly Data Feed-June 2019.csv\n",
      "Downloaded Copy of Monthly Data Feed-July 2019.csv\n",
      "Downloaded Monthly Data Feed-August 2019.csv\n",
      "Downloaded Monthly Data feed September 2019.csv\n",
      "Downloaded Monthly Data Feed October 2019.csv\n",
      "Downloaded Monthly Data Feed - Nov 2019.csv\n",
      "Downloaded Monthly Data Feed - Dec 2019.csv\n",
      "Downloaded Christmas analysis.csv\n",
      "Downloaded Jan 2020.csv\n",
      "Downloaded Feb 2020.csv\n",
      "Downloaded Mar 2020.csv\n",
      "Downloaded Monthly Data feed April 2020.csv\n",
      "Downloaded Copy of Monthly Data Feed - May 2020.csv\n",
      "Downloaded 1.06.20 - 07.06.20.csv\n",
      "Downloaded 08.06.20 - 14.06.20.csv\n",
      "Downloaded 15.06.20 - 21.06.20.csv\n",
      "Downloaded 22.06.20 - 28.06.20.csv\n",
      "Downloaded 29.06.2020 - 05.07.2020.csv\n",
      "Downloaded 06.07.20 - 12.07.20.csv\n",
      "Downloaded 13.07.20 - 19.07.20.csv\n",
      "Downloaded 20.07.20 - 26.07.20.csv\n",
      "Downloaded 27.07.20 - 02.08.20.csv\n",
      "Downloaded 03.08.20 -09.08.20.csv\n",
      "Downloaded 10.08.20 - 16.08.20.csv\n",
      "Downloaded 17.08.20 - 23.08.20.csv\n",
      "Downloaded 24.08.20 - 30.08.20.csv\n",
      "Downloaded 31.08.20 - 06.09.20.csv\n",
      "Downloaded 07.09.20 - 13.09.20.csv\n",
      "Downloaded 14.09.20 - 20.09.20.csv\n",
      "Downloaded 21.09.20 - 27.09.20.csv\n",
      "Downloaded 28.09.20 - 04.10.20.csv\n",
      "Downloaded 05.10.20 to 11.10.20.csv\n",
      "Downloaded 12.10.20 - 18.10.20.csv\n",
      "Downloaded Weekly Data 19.10.20 - 25.10.20.csv\n",
      "Downloaded Weekly Data 26.10.20 - 01.11.20.csv\n",
      "Downloaded Weekly Data 02.11.20 - 08.11.20.csv\n",
      "Downloaded 09.11.2020 - 15.11.2020.csv\n",
      "Downloaded 16.11.2020 - 22.11.2020.csv\n",
      "Downloaded 23.11.2020 - 29.11.2020.csv\n",
      "Downloaded 30.11.2020 - 06.12.2020.csv\n",
      "Downloaded Weekly Data 07.12.20 - 13.12.20.csv\n",
      "Downloaded Weekly Data 14.12.20 - 20.12.20.csv\n",
      "Downloaded Weekly Data 21.12.20 - 27.12.20.csv\n",
      "Downloaded Weekly Data 28.12.20 - 03.01.21.csv\n",
      "Downloaded Weekly Data 04.01.21 - 10.01.21.csv\n",
      "Downloaded Weekly Data 11.01.21 - 17.01.21.csv\n",
      "Downloaded Weekly Data 18.01.21 - 24.01.21.csv\n",
      "Downloaded Weekly Data 25.01.21 - 31.01.21.csv\n",
      "Downloaded weekly Data 01.02.21 - 07.01.21.csv\n",
      "Downloaded weekly Data 08.02.21 - 14.02.21.csv\n",
      "Downloaded Weekly Data 15.02.21 - 21.02.21.csv\n",
      "Downloaded Weekly Data 22.02.21 - 28.02.21.csv\n",
      "Downloaded Weekly Data 01.03.21 - 07.03.21.csv\n",
      "Downloaded Weekly Data 08.03.21 - 14.03.21.csv\n",
      "Downloaded Weekly Data 15.03.21 - 21.03.21.csv\n",
      "Downloaded Weekly Data 22.03.21 - 28.03.21.csv\n",
      "Downloaded Weekly Data 29.03.21 - 04.04.21.csv\n",
      "Downloaded Weekly Data 05.04.21 - 11.04.21.csv\n",
      "Downloaded Weekly Data 12.04.21 - 18.04.21.csv\n",
      "Downloaded Weekly Data 19.04.21 - 25.04.21.csv\n",
      "Downloaded Weekly Data 26.04.21 - 02.05.2021.csv\n",
      "Downloaded Weekly Data 03.05.21 - 09.05.21.csv\n",
      "Downloaded Weekly Data 10.05.21 - 16.05.21.csv\n",
      "Downloaded Weekly Data 17.05.21 - 23-05.21.csv\n",
      "Downloaded Weekly Data 24.05.21 - 30.05.21.csv\n",
      "Downloaded Weekly Data 31.05.21 - 06.06.21.csv\n",
      "Downloaded Weekly Data 07.06.21 - 13.06.21.csv\n",
      "Downloaded Weekly Data 14.06.21 - 20.06.21.csv\n",
      "Downloaded Weekly Data 21.06.21 - 27.06.21.csv\n",
      "Downloaded Weekly Data 28.06.21 - 04.07.21.csv\n",
      "Downloaded Weekly Data 05.07.21 - 11.07.21.csv\n",
      "Downloaded Weekly Data 12.07.21 - 18.07.21.csv\n",
      "Downloaded Weekly Data 19.07.21 - 25.07.21.csv\n",
      "Downloaded Weekly Data 26.07.21 - 01.08.21.csv\n",
      "Downloaded Weekly Data 02.08.21 - 08.08.21.csv\n",
      "Downloaded Weekly Data 09.08.21 - 15.08.21.csv\n",
      "Downloaded Weekly Data 16.08.21 - 22.08.21.csv\n",
      "Downloaded Weekly Data 23.08.21 - 29.08.21.csv\n",
      "Downloaded Weekly Data 30.08.21 - 05.09.21.csv\n",
      "Downloaded Weekly Data 06.09.21 - 12.09.21.csv\n",
      "Downloaded Weekly Data 13.09.21 - 19.09.21.csv\n",
      "Downloaded Weekly Data 20.09.21 - 26.09.21.csv\n",
      "Downloaded Weekly Data 27.09.21 - 03.10.21.csv\n",
      "Downloaded Weekly Data 04.10.21 - 10.10.21.csv\n",
      "Downloaded Weekly Data 11.10.21 - 17.10.21.csv\n",
      "Downloaded Weekly Data 18.10.21 - 24.10.21.csv\n",
      "Downloaded Weekly Data 25.10.21 - 31.10.21.csv\n",
      "Downloaded Weekly Data 01.11.21 - 07.11.21.csv\n",
      "Downloaded Weekly Data 08.11.21 - 14.11.21.csv\n",
      "Downloaded Weekly Data 15.11.21 - 21.11.21.csv\n",
      "Downloaded Weekly Data 22.11.21 - 28.11.21.csv\n",
      "Downloaded Weekly Data 29.11.21 - 05.12.21.csv\n",
      "Downloaded Weekly Data 06.12.21 - 12.12.21.csv\n",
      "Downloaded Weekly Data 13.12.21 - 19.12.21.csv\n",
      "Downloaded Weekly Data 20.12.21 - 26.12.21.csv\n",
      "Downloaded Weekly Data 27.12.21 - 02.01.22.csv\n",
      "Downloaded Weekly Data 03.01.22 - 09.01.22.csv\n",
      "Downloaded Weekly Data 10.01.22 - 16.01.22.csv\n",
      "Downloaded Weekly Data 17.01.22 - 23.01.22.csv\n",
      "Downloaded Weekly Data 24.01.22 - 30.01.22.csv\n",
      "Downloaded Weely Data 31.01.22 - 06.02.22.csv\n",
      "Downloaded Weekly Data 07.02.22 - 13.02.22.csv\n",
      "Downloaded Weekly Data 14.02.22 - 20.02.22.csv\n",
      "Downloaded Weekly Data 21.02.22 - 27.02.22.csv\n",
      "Downloaded Weekly Data 28.02.22 - 06.03.22.csv\n",
      "Downloaded Weekly Data 07.03.22 - 13.03.22.csv\n",
      "Downloaded Weekly Data 14.03.22 - 20.03.22.csv\n",
      "Downloaded Weekly Data 21.03.22 - 27.03.22.csv\n",
      "Downloaded Weekly Data 28.03.22 - 03.04.22.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Weekly Data 04.04.22 - 10.04.22.csv\n",
      "Downloaded Weekly Data 11.04.22 - 17.04.2022.csv\n",
      "Downloaded Weekly Data 18.04.22 - 24.04.22.csv\n",
      "Downloaded Weekly Data 25.04.22 - 01.05.22.csv\n",
      "Downloaded Weekly Data 02.05.22 - 08.05.22.csv\n",
      "Downloaded Weekly Data 09.05.22 - 15.05.22.csv\n",
      "Downloaded Weekly Data 16.05.22 - 22.05.22.csv\n",
      "Downloaded Weekly Data 23.05.22 - 29.05.22.csv\n",
      "Downloaded Weekly Data 30.05.22 - 05.06.22.csv\n",
      "Downloaded Weekly Data 06.06.22 - 12.06.22.csv\n",
      "Downloaded Weekly Data 13.06.22 - 19.06.22.csv\n",
      "Downloaded Weekly Data 20.06.22 - 26.06.22.csv\n",
      "Downloaded Weekly Data 27.06.22 - 03.07.22.csv\n",
      "Downloaded Weekly Data 04.07.22 - 10.07.22.csv\n",
      "Downloaded Weekly Data 11.07.22 - 17.07.22.csv\n",
      "Downloaded Weekly Data 18.07.22 - 24.07.22.csv\n",
      "Downloaded Weekly Data 25.07.22 - 31.07.22.csv\n",
      "Downloaded Weekly Data 01.08.22 - 07.08.22.csv\n",
      "Downloaded Weekly Data 08.08.22 - 14.08.22.csv\n",
      "Downloaded Weekly Data 15.08.22 - 21.08.22.csv\n",
      "Downloaded Weekly Data 22.08.22 - 28.08.22.csv\n",
      "Downloaded Weekly Data 29.08.22 - 04.09.22.csv\n",
      "Downloaded Weekly Data 05.09.22 - 11.09.22.csv\n",
      "Downloaded Weekly Data 12.09.22 - 18.09.22.csv\n",
      "Downloaded Weekly Data 19.09.22 - 25.09.22.csv\n",
      "Downloaded Weekly Data 26.09.22 - 02.10.22.csv\n",
      "Downloaded Weekly Data 03.10.22 - 09.10.22.csv\n",
      "Downloaded Weekly Data 10.10.22 - 16.10.22.csv\n",
      "Downloaded Weekly Data 17.10.22 - 23.10.22.csv\n",
      "Downloaded Weekly Data 24.10.22 - 30.10.22.csv\n",
      "Downloaded Weekly Data 31.10.22 - 06.11.22.csv\n",
      "Downloaded Weekly Data 07.11.22 - 13.11.22.csv\n",
      "Downloaded Weekly Data 14.11.22 - 20.11.22.csv\n",
      "Downloaded Weekly Data 21.11.22 - 27.11.22.csv\n",
      "Downloaded Weekly Data 28.11.22 - 04.12.22.csv\n",
      "Downloaded Weekly Data 05.12.22 - 11.12.22.csv\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-5-0c53b35dd61c>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-0c53b35dd61c>\"\u001b[1;36m, line \u001b[1;32m25\u001b[0m\n\u001b[1;33m    return file_list\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "local_storage ='files/'\n",
    "\n",
    "if not os.path.exists(local_storage):\n",
    "    os.makedirs(local_storage)\n",
    "\n",
    "r = requests.get('https://datamillnorth.org/api/dataset/leeds-city-centre-footfall-data')\n",
    "api_response = r.json()\n",
    "\n",
    "file_list = []\n",
    "for key, file in api_response['resources'].items():\n",
    "    if file['format'] == 'csv':\n",
    "        file_name = file['url'].split('/')[-1]\n",
    "        url = f'https://datamillnorth.org/download/leeds-city-centre-footfall-data/{key}/{file_name}'\n",
    "\n",
    "        file_name = file_name.replace('%20',' ')\n",
    "        response = requests.get(url)\n",
    "        with open(os.path.join(local_storage, file_name), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f'Downloaded {file_name}')\n",
    "        file_list.append(file_name)\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load to dataframes\n",
    "Load each of the files into a pandas dataframe for analysis.\n",
    "\n",
    "At the same time, create a dataframe containing a summary of each file, including the number of rows and the columns in the file, to give us a good idea of each of the different formats we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "raw_dataframes = {}\n",
    "summaries = []\n",
    "for filename in file_list:\n",
    "    df_file = pd.read_csv(f'{local_storage}{filename}')\n",
    "    \n",
    "    raw_dataframes[filename] = df_file\n",
    "    \n",
    "    summary = {\n",
    "        'filename': filename,\n",
    "        'columns': sorted(list(df_file.columns)),\n",
    "        'columns_str': ', '.join(sorted(list(df_file.columns))),\n",
    "        'columns_cnt': len(list(df_file.columns)),\n",
    "        'rows': len(df_file)\n",
    "    }\n",
    "    summaries.append(summary)\n",
    "\n",
    "    \n",
    "df_summary = pd.DataFrame(summaries)\n",
    "print('Loaded')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine dataframe types\n",
    "Let's have a look at the various data formats available, based on the column headers. We'll assign an identifier, column_group, to each unique combination of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns_str</th>\n",
       "      <th>column_group</th>\n",
       "      <th>total_files</th>\n",
       "      <th>total_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017, 2018, 2019, Unnamed: 1, Unnamed: 10, Unnamed: 11, Unnamed: 12, Unnamed: 2, Unnamed: 3, Unnamed: 5, Unnamed: 6, Unnamed: 7, Unnamed: 9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>155904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>24192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>17280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site, Unnamed: 14, Unnamed: 15, Unnamed: 16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site</td>\n",
       "      <td>6</td>\n",
       "      <td>152</td>\n",
       "      <td>261744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>60246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>386112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                           columns_str  \\\n",
       "0                                                                                                          2017, 2018, 2019, Unnamed: 1, Unnamed: 10, Unnamed: 11, Unnamed: 12, Unnamed: 2, Unnamed: 3, Unnamed: 5, Unnamed: 6, Unnamed: 7, Unnamed: 9   \n",
       "1  BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday   \n",
       "2                                                                                                                          BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday   \n",
       "3                                                                                                                                                               BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday   \n",
       "4                                                                                        BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site   \n",
       "5                                                 BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site, Unnamed: 14, Unnamed: 15, Unnamed: 16   \n",
       "6                                                                    BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site   \n",
       "7                                                                                   BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site   \n",
       "8                                                                                                                                                                                       Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year   \n",
       "\n",
       "   column_group  total_files  total_rows  \n",
       "0             0            1          79  \n",
       "1             1           27      155904  \n",
       "2             2            4       24192  \n",
       "3             3            1       23424  \n",
       "4             4            3       17280  \n",
       "5             5            1        6912  \n",
       "6             6          152      261744  \n",
       "7             7           17       60246  \n",
       "8             8            8      386112  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a unique identifier for each columns combination\n",
    "df_summary['column_group'] = df_summary.groupby(['columns_str']).grouper.group_info[0]\n",
    "\n",
    "# summarise each group\n",
    "df_columns = (df_summary.groupby(['columns_str', 'column_group'])['rows']\n",
    "    .agg(['count', 'sum'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'count': 'total_files','sum': 'total_rows'}))\n",
    "    \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this summary we can take a few notes:\n",
    "1. Several files have columns that are coming through as \"Unnamed: xx\". These can be dropped.\n",
    "1. There are some consistent fields in each file which we are interested in, such as Date and Hour, and there are others which seem to change name, such as LocationName/Location. Due to the similarities in field names, we can take educated guesses as to which fields are the same.\n",
    "1. Column group 5 appears to have the same columns as group 6, but has additional Unnamed fields at the end. Once unnamed fields are dropped, this will reduce the group counts down.\n",
    "1. The number of files that a given set of fields appear in is no indication of how many rows of data are effected. Group 8 has just 8 files with that combination of fields yet it has more rows than group 6 152 files (386112 vs 261744). This is because several of the files summarise long periods of time, whereas others cover just a single week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 0 - valid file?\n",
    "Group 0 appears to be wildly different to the rest. Let's examine that file specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christmas analysis.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>2018</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>2019</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>16-Oct-17</td>\n",
       "      <td>128744.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>17-Oct-17</td>\n",
       "      <td>128842.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>16-Oct-18</td>\n",
       "      <td>131208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>18-Oct-17</td>\n",
       "      <td>135502.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>17-Oct-18</td>\n",
       "      <td>134874.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>16-Oct-19</td>\n",
       "      <td>129199.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUITE BUSY: above average footfall for the period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>19-Oct-17</td>\n",
       "      <td>120944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>18-Oct-18</td>\n",
       "      <td>134372.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>17-Oct-19</td>\n",
       "      <td>134760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VERY BUSY: +30% above average footfall for the period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>20-Oct-17</td>\n",
       "      <td>154793.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>19-Oct-18</td>\n",
       "      <td>150036.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>18-Oct-19</td>\n",
       "      <td>145461.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXTREMELY BUSY: +50% above average footfall for the period</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2017 Unnamed: 1  Unnamed: 2  Unnamed: 3       2018 Unnamed: 5  \\\n",
       "0     Monday  16-Oct-17    128744.0         NaN        NaN        NaN   \n",
       "1    Tuesday  17-Oct-17    128842.0         NaN    Tuesday  16-Oct-18   \n",
       "2  Wednesday  18-Oct-17    135502.0         NaN  Wednesday  17-Oct-18   \n",
       "3   Thursday  19-Oct-17    120944.0         NaN   Thursday  18-Oct-18   \n",
       "4     Friday  20-Oct-17    154793.0         NaN     Friday  19-Oct-18   \n",
       "\n",
       "   Unnamed: 6  Unnamed: 7       2019 Unnamed: 9  Unnamed: 10  Unnamed: 11  \\\n",
       "0         NaN         NaN        NaN        NaN          NaN          NaN   \n",
       "1    131208.0         NaN        NaN        NaN          NaN          NaN   \n",
       "2    134874.0         NaN  Wednesday  16-Oct-19     129199.0          NaN   \n",
       "3    134372.0         NaN   Thursday  17-Oct-19     134760.0          NaN   \n",
       "4    150036.0         NaN     Friday  18-Oct-19     145461.0          NaN   \n",
       "\n",
       "                                                  Unnamed: 12  \n",
       "0                                                         NaN  \n",
       "1                                                         NaN  \n",
       "2           QUITE BUSY: above average footfall for the period  \n",
       "3       VERY BUSY: +30% above average footfall for the period  \n",
       "4  EXTREMELY BUSY: +50% above average footfall for the period  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the filename\n",
    "filename = df_summary[(df_summary['column_group']==0)]['filename'].iloc[0]\n",
    "print(filename)\n",
    "\n",
    "# Show us that dataframe\n",
    "raw_dataframes[filename].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this file, Christmas analysis.csv, and it is clear that it is some sort of ad-hoc analysis, which is not relevant nor with useful data for our purposes. This can be confirmed by visiting the DataMillNorth page and viewing the notes for this file. It can be excluded when building the historic picture.\n",
    "It also indicates the possibility of files that are not useful and would result in errors in a data pipeline. We must build in the option to ignore specific files in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Dataframes\n",
    "Based on this initial examination, we can reload the dataframes and fix some of the data issues immediately:\n",
    "1. Ignore Christmas analysis.csv\n",
    "1. Remove any columns titled Unnamed: xx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns_str</th>\n",
       "      <th>column_group</th>\n",
       "      <th>total_files</th>\n",
       "      <th>total_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>155904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>261744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>60246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>386112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                           columns_str  \\\n",
       "0  BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday   \n",
       "1                                                                                                                          BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday   \n",
       "2                                                                                                                                                               BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday   \n",
       "3                                                                                        BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site   \n",
       "4                                                                    BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site   \n",
       "5                                                                                   BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site   \n",
       "6                                                                                                                                                                                       Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year   \n",
       "\n",
       "   column_group  total_files  total_rows  \n",
       "0             0           27      155904  \n",
       "1             1            4       24192  \n",
       "2             2            1       23424  \n",
       "3             3            4       24192  \n",
       "4             4          152      261744  \n",
       "5             5           17       60246  \n",
       "6             6            8      386112  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataframes = {}\n",
    "summaries = []\n",
    "for filename in file_list:\n",
    "    # Ignore the adhoc analysis file\n",
    "    if filename == 'Christmas analysis.csv':\n",
    "        continue\n",
    "        \n",
    "    df_file = pd.read_csv(f'{local_storage}{filename}')\n",
    "    \n",
    "    # Remove any \n",
    "    df_file.drop(df_file.columns[df_file.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "        \n",
    "    \n",
    "    raw_dataframes[filename] = df_file\n",
    "    \n",
    "    summary = {\n",
    "        'filename': filename,\n",
    "        'columns': sorted(list(df_file.columns)),\n",
    "        'columns_str': ', '.join(sorted(list(df_file.columns))),\n",
    "        'columns_cnt': len(list(df_file.columns)),\n",
    "        'rows': len(df_file)\n",
    "    }\n",
    "    summaries.append(summary)\n",
    "\n",
    "    \n",
    "df_summary = pd.DataFrame(summaries)\n",
    "print('Loaded')\n",
    "\n",
    "# Create a unique identifier for each columns combination\n",
    "df_summary['column_group'] = df_summary.groupby(['columns_str']).grouper.group_info[0]\n",
    "\n",
    "# summarise each group\n",
    "df_columns = (df_summary.groupby(['columns_str', 'column_group'])['rows']\n",
    "    .agg(['count', 'sum'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'count': 'total_files','sum': 'total_rows'}))\n",
    "    \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have cut the number of data formats down to 7 now, each of them unique.\n",
    "\n",
    "For each format, we're going to view which fields are the right ones we want to use based on a sample file for that data format, and note any other data format issues we need to clear up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine individual data formats\n",
    "First we need to grab a sample file for each data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>columns</th>\n",
       "      <th>columns_str</th>\n",
       "      <th>columns_cnt</th>\n",
       "      <th>rows</th>\n",
       "      <th>column_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>monthly-data-feed-aug-2014-20140904.csv</td>\n",
       "      <td>[BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday]</td>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday</td>\n",
       "      <td>12</td>\n",
       "      <td>5376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv</td>\n",
       "      <td>[BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday]</td>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday</td>\n",
       "      <td>19</td>\n",
       "      <td>5952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>Copy of Monthly Data Feed - Oct 2017.csv</td>\n",
       "      <td>[BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site]</td>\n",
       "      <td>BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site</td>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>footfall.csv</td>\n",
       "      <td>[BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday]</td>\n",
       "      <td>BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday</td>\n",
       "      <td>9</td>\n",
       "      <td>23424</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Copy of Monthly Data Feed-February 2017 - 20170301.csv</td>\n",
       "      <td>[BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site]</td>\n",
       "      <td>BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site</td>\n",
       "      <td>14</td>\n",
       "      <td>5376</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>albion-street-north.csv</td>\n",
       "      <td>[Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year]</td>\n",
       "      <td>Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year</td>\n",
       "      <td>8</td>\n",
       "      <td>47856</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61</td>\n",
       "      <td>01.10.2018 - 31.10.2018.csv</td>\n",
       "      <td>[BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site]</td>\n",
       "      <td>BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site</td>\n",
       "      <td>15</td>\n",
       "      <td>4464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                  filename  \\\n",
       "0     25                   monthly-data-feed-aug-2014-20140904.csv   \n",
       "1     31  Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv   \n",
       "2     45                  Copy of Monthly Data Feed - Oct 2017.csv   \n",
       "3     48                                              footfall.csv   \n",
       "4     50    Copy of Monthly Data Feed-February 2017 - 20170301.csv   \n",
       "5     56                                   albion-street-north.csv   \n",
       "6     61                               01.10.2018 - 31.10.2018.csv   \n",
       "\n",
       "                                                                                                                                                                                                                                                 columns  \\\n",
       "0                                                                                                                          [BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday]   \n",
       "1  [BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday]   \n",
       "2                                                                                   [BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site]   \n",
       "3                                                                                                                                                               [BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday]   \n",
       "4                                                                                        [BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site]   \n",
       "5                                                                                                                                                                                       [Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year]   \n",
       "6                                                                    [BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site]   \n",
       "\n",
       "                                                                                                                                                                                                                                           columns_str  \\\n",
       "0                                                                                                                          BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationGroup, LocationName, OutCount, TotalCount, Weekday   \n",
       "1  BRCMonthName, BRCQuarter, BRCWeek, BRCYear, BusinessInCount, BusinessOutCount, BusinessTotalCount, Date, FactoredInCount, FactoredOutCount, FactoredTotalCount, Hour, InCount, LocationGroup, LocationName, OutCount, Sitename, TotalCount, Weekday   \n",
       "2                                                                                   BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationName, OutCount, ReportCount, Site   \n",
       "3                                                                                                                                                               BRCMonthName, BRCQuarter, BRCWeek, BRCYear, Date, Hour, InCount, LocationName, Weekday   \n",
       "4                                                                                        BRCMonthName, BRCWeek, BRCYear, Date, DayOfWeek, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, Location, OutCount, ReportCount, Site   \n",
       "5                                                                                                                                                                                       Count, Date, Hour, LocationName, Month, WeekDay, WeekNum, Year   \n",
       "6                                                                    BRCMonthName, BRCWeekNum, BRCYear, Date, DayName, FactoredInCount, FactoredOutCount, FactoredReportCount, Hour, InCount, LocationGroup, LocationName, OutCount, ReportCount, Site   \n",
       "\n",
       "   columns_cnt   rows  column_group  \n",
       "0           12   5376             1  \n",
       "1           19   5952             0  \n",
       "2           14    224             5  \n",
       "3            9  23424             2  \n",
       "4           14   5376             3  \n",
       "5            8  47856             6  \n",
       "6           15   4464             4  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samples = df_summary[df_summary.groupby('columns_str')['filename'].rank() == 1].reset_index()\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go through and view the sample files. For each group/file we'll determine which field corresponds to our required output field, and put any additional notes on data formats.\n",
    "\n",
    "Each of the df.head() commands below was uncommented in turn, manually examined and then notes made on which fields correspond to which. Only one group's command has been uncommented below for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>LocationName</th>\n",
       "      <th>BRCYear</th>\n",
       "      <th>BRCMonthName</th>\n",
       "      <th>BRCWeekNum</th>\n",
       "      <th>DayName</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>InCount</th>\n",
       "      <th>OutCount</th>\n",
       "      <th>ReportCount</th>\n",
       "      <th>FactoredInCount</th>\n",
       "      <th>FactoredOutCount</th>\n",
       "      <th>FactoredReportCount</th>\n",
       "      <th>TotalFootfall</th>\n",
       "      <th>FootfallLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>Albion Street North</td>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>40</td>\n",
       "      <td>Monday</td>\n",
       "      <td>02-Oct-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28725</td>\n",
       "      <td>0</td>\n",
       "      <td>28725</td>\n",
       "      <td>28725</td>\n",
       "      <td>0</td>\n",
       "      <td>28725</td>\n",
       "      <td>28725</td>\n",
       "      <td>Albion Street North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>Albion Street North</td>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>40</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>03-Oct-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28303</td>\n",
       "      <td>0</td>\n",
       "      <td>28303</td>\n",
       "      <td>28303</td>\n",
       "      <td>0</td>\n",
       "      <td>28303</td>\n",
       "      <td>28303</td>\n",
       "      <td>Albion Street North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>Albion Street North</td>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>40</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>04-Oct-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24663</td>\n",
       "      <td>0</td>\n",
       "      <td>24663</td>\n",
       "      <td>24663</td>\n",
       "      <td>0</td>\n",
       "      <td>24663</td>\n",
       "      <td>24663</td>\n",
       "      <td>Albion Street North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>Albion Street North</td>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>40</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>05-Oct-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33531</td>\n",
       "      <td>0</td>\n",
       "      <td>33531</td>\n",
       "      <td>33531</td>\n",
       "      <td>0</td>\n",
       "      <td>33531</td>\n",
       "      <td>33531</td>\n",
       "      <td>Albion Street North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>Albion Street North</td>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>40</td>\n",
       "      <td>Friday</td>\n",
       "      <td>06-Oct-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38260</td>\n",
       "      <td>0</td>\n",
       "      <td>38260</td>\n",
       "      <td>38260</td>\n",
       "      <td>0</td>\n",
       "      <td>38260</td>\n",
       "      <td>38260</td>\n",
       "      <td>Albion Street North</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site         LocationName  BRCYear BRCMonthName  BRCWeekNum    DayName  \\\n",
       "0  Leeds  Albion Street North     2017      October          40     Monday   \n",
       "1  Leeds  Albion Street North     2017      October          40    Tuesday   \n",
       "2  Leeds  Albion Street North     2017      October          40  Wednesday   \n",
       "3  Leeds  Albion Street North     2017      October          40   Thursday   \n",
       "4  Leeds  Albion Street North     2017      October          40     Friday   \n",
       "\n",
       "        Date  Hour  InCount  OutCount  ReportCount  FactoredInCount  \\\n",
       "0  02-Oct-17   NaN    28725         0        28725            28725   \n",
       "1  03-Oct-17   NaN    28303         0        28303            28303   \n",
       "2  04-Oct-17   NaN    24663         0        24663            24663   \n",
       "3  05-Oct-17   NaN    33531         0        33531            33531   \n",
       "4  06-Oct-17   NaN    38260         0        38260            38260   \n",
       "\n",
       "   FactoredOutCount  FactoredReportCount  TotalFootfall     FootfallLocation  \n",
       "0                 0                28725          28725  Albion Street North  \n",
       "1                 0                28303          28303  Albion Street North  \n",
       "2                 0                24663          24663  Albion Street North  \n",
       "3                 0                33531          33531  Albion Street North  \n",
       "4                 0                38260          38260  Albion Street North  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group 0\n",
    "#raw_dataframes['Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv'].head()\n",
    "\n",
    "# Group 1\n",
    "#raw_dataframes['monthly-data-feed-aug-2014-20140904.csv'].head()\n",
    "\n",
    "# Group 2\n",
    "#raw_dataframes['footfall.csv'].head()\n",
    "\n",
    "# Group 3\n",
    "#raw_dataframes['Copy of Monthly Data Feed-February 2017 - 20170301.csv'].head()\n",
    "\n",
    "# Group 4\n",
    "#raw_dataframes['01.10.2018 - 31.10.2018.csv'].head()\n",
    "\n",
    "# Group 5\n",
    "raw_dataframes['Copy of Monthly Data Feed - Oct 2017.csv'].head()\n",
    "\n",
    "# Group 6\n",
    "#raw_dataframes['albion-street-north.csv'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "The groupings and their field mappings are noted below.\n",
    "\n",
    "|Group|File|Location|Date|Hour|ReportCount|Notes|\n",
    "|:-|:-|:-|:-|:-|:-|:-|\n",
    "|0|Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv|LocationName|Date|Hour|TotalCount||\n",
    "|1|monthly-data-feed-aug-2014-20140904.csv|LocationName|Date|Hour|TotalCount||\n",
    "|2|footfall.csv|LocationName|Date|Hour|InCount||\n",
    "|3|Copy of Monthly Data Feed-February 2017 - 20170301.csv|Location|Date|Hour|ReportCount||\n",
    "|4|01.10.2018 - 31.10.2018.csv|LocationName|Date|Hour|ReportCount||\n",
    "|5|Copy of Monthly Data Feed - Oct 2017.csv|LocationName|Date|Hour|ReportCount|!Hour field is null|\n",
    "|6|albion-street-north.csv|LocationName|Date|Hour|Count||\n",
    "\n",
    "#### Group 5 - Daily, not hourly\n",
    "Of important note is group 5. The sample file, Copy of Monthly Data Feed - Oct 2017.csv, appears to be broken down by day, not by hour. This indicates that we should filter out files which do not have valid hour values.\n",
    "\n",
    "#### Date and time formats\n",
    "After viewing the different files, it is clear that the date and hour formats are inconsistent. Dates are sometimes given as dd-mmm-yy, other times as dd/mm/yy. Hours are sometimes presented as a single hour number and other times as HH:MM. Functions will need to be written to fix these.\n",
    "\n",
    "#### Renaming count columns\n",
    "While LocationName, Date and Hour are consistent across files, the actual column which counts the total footfall is not. Some files have Count, TotalCount or InCount instead. To complicate a simple renaming, some files have both ReportCount and one of the others. Therefore a simple renaming will not work. Renaming Count to ReportCount won't work if there's already a ReportCount column. Instead the renaming must only take place if there isn't a ReportCount already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date formats\n",
    "Pandas natively includes a function for automatically converting date formats: pd.to_datetime(). This can be applied to the Date column as a standard import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-03 00:00:00\n",
      "2023-03-02 00:00:00\n",
      "2023-03-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "test_data = ['02/03/23', '02-Mar-23','2023-03-02']\n",
    "\n",
    "for value in test_data:\n",
    "    print(pd.to_datetime(value, infer_datetime_format=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hour Formats\n",
    "This function uses regex to extract the hour value from given text and returns it in HH:MM:SS format, ready for conversion to a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value '01:00' is reformatted to '01:00:00'\n",
      "Value '01' is reformatted to '01:00:00'\n",
      "Value '1' is reformatted to '01:00:00'\n",
      "Value '1' is reformatted to '01:00:00'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_hours(x):\n",
    "    x = str(x)\n",
    "    try:\n",
    "        return re.search(r\"^([0-9]{1,2})(?:\\.|\\:|$)\", x).group(1).rjust(2,'0') + ':00:00'\n",
    "    except:\n",
    "        return '00:00:00'\n",
    "    \n",
    "    \n",
    "test_data = ['01:00','01','1',1]\n",
    "\n",
    "for value in test_data:\n",
    "    #data_type = type(value)\n",
    "    output = clean_hours(value)\n",
    "    print(f'Value \\'{value}\\' is reformatted to \\'{output}\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footfall Total Column Name Conversion\n",
    "This function has an ordered list of potential columns to use as the footfall figure. As soon as it finds the first matching column name, it creates a TotalFootfall column based on that one and then exits the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to find a source footfall column for Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv...\n",
      "Used TotalCount\n",
      "Attempting to find a source footfall column for monthly-data-feed-aug-2014-20140904.csv...\n",
      "Used TotalCount\n",
      "Attempting to find a source footfall column for footfall.csv...\n",
      "Used InCount\n",
      "Attempting to find a source footfall column for Copy of Monthly Data Feed-February 2017 - 20170301.csv...\n",
      "Used ReportCount\n",
      "Attempting to find a source footfall column for 01.10.2018 - 31.10.2018.csv...\n",
      "Used ReportCount\n",
      "Attempting to find a source footfall column for Copy of Monthly Data Feed - Oct 2017.csv...\n",
      "Used ReportCount\n",
      "Attempting to find a source footfall column for albion-street-north.csv...\n",
      "Used Count\n"
     ]
    }
   ],
   "source": [
    "def get_footfall_column(df):\n",
    "    prefered_source_columns = [\n",
    "        'ReportCount',\n",
    "        'TotalCount',\n",
    "        'InCount',\n",
    "        'Count'\n",
    "    ]\n",
    "    \n",
    "    for source in prefered_source_columns:\n",
    "        if source in list(df.columns):\n",
    "            df['TotalFootfall'] = df[source]\n",
    "            print(f'Used {source}')\n",
    "            return df\n",
    "        \n",
    "    print('No source column found')\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "test_data = [\n",
    "    'Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv',\n",
    "    'monthly-data-feed-aug-2014-20140904.csv',\n",
    "    'footfall.csv',\n",
    "    'Copy of Monthly Data Feed-February 2017 - 20170301.csv',\n",
    "    '01.10.2018 - 31.10.2018.csv',\n",
    "    'Copy of Monthly Data Feed - Oct 2017.csv',\n",
    "    'albion-street-north.csv'\n",
    "]\n",
    "\n",
    "for value in test_data:\n",
    "    print(f'Attempting to find a source footfall column for {value}...')\n",
    "    x = get_footfall_column(raw_dataframes[value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Column Name Conversion\n",
    "This function follows the exact same pattern as the footfall column conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to find a source location column for Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv...\n",
      "Used LocationName\n",
      "Attempting to find a source location column for monthly-data-feed-aug-2014-20140904.csv...\n",
      "Used LocationName\n",
      "Attempting to find a source location column for footfall.csv...\n",
      "Used LocationName\n",
      "Attempting to find a source location column for Copy of Monthly Data Feed-February 2017 - 20170301.csv...\n",
      "Used Location\n",
      "Attempting to find a source location column for 01.10.2018 - 31.10.2018.csv...\n",
      "Used LocationName\n",
      "Attempting to find a source location column for Copy of Monthly Data Feed - Oct 2017.csv...\n",
      "Used LocationName\n",
      "Attempting to find a source location column for albion-street-north.csv...\n",
      "Used LocationName\n"
     ]
    }
   ],
   "source": [
    "def get_location_column(df):\n",
    "    prefered_source_columns = [\n",
    "        'LocationName',\n",
    "        'Location'\n",
    "    ]\n",
    "    \n",
    "    for source in prefered_source_columns:\n",
    "        if source in list(df.columns):\n",
    "            df['FootfallLocation'] = df[source]\n",
    "            print(f'Used {source}')\n",
    "            return df\n",
    "        \n",
    "    print(f'No location column found')\n",
    "    return False\n",
    "\n",
    "test_data = [\n",
    "    'Copy of Monthly Data Feed-August 2016 - 20160905 (2).csv',\n",
    "    'monthly-data-feed-aug-2014-20140904.csv',\n",
    "    'footfall.csv',\n",
    "    'Copy of Monthly Data Feed-February 2017 - 20170301.csv',\n",
    "    '01.10.2018 - 31.10.2018.csv',\n",
    "    'Copy of Monthly Data Feed - Oct 2017.csv',\n",
    "    'albion-street-north.csv'\n",
    "]\n",
    "\n",
    "for value in test_data:\n",
    "    print(f'Attempting to find a source location column for {value}...')\n",
    "    x = get_location_column(raw_dataframes[value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! 248 hour values missing in Monthly Data Feed - Dec 2017.csv.\n",
      "Warning! 192 hour values missing in Monthly Data Feed-April 2017 - 20170510.csv.\n",
      "Warning! 248 hour values missing in Monthly Data Feed -  Jan 2018.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-166-f33031f9e48c>:68: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_file['Date'] = pd.to_datetime(df_file['Date'], infer_datetime_format=True)\n",
      "<ipython-input-166-f33031f9e48c>:68: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_file['Date'] = pd.to_datetime(df_file['Date'], infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! 280 hour values missing in Copy of Monthly Data Feed - Sept 2017.csv.\n",
      "Warning! 1152 hour values missing in Copy of Monthly Data Feed-November 2016 - 20161221.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-166-f33031f9e48c>:68: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_file['Date'] = pd.to_datetime(df_file['Date'], infer_datetime_format=True)\n",
      "<ipython-input-166-f33031f9e48c>:68: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_file['Date'] = pd.to_datetime(df_file['Date'], infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! 240 hour values missing in Monthly Data Feed - Nov 2017.csv.\n",
      "Warning! 248 hour values missing in Monthly Data Feed-March 2018.csv.\n",
      "Warning! 224 hour values missing in Copy of Monthly Data Feed - Oct 2017.csv.\n",
      "Warning! 224 hour values missing in Monthly Data Feed-Feb 2018.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-166-f33031f9e48c>:68: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_file['Date'] = pd.to_datetime(df_file['Date'], infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FootfallLocation</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>TotalFootfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headrow</td>\n",
       "      <td>2008-08-27 00:00:00</td>\n",
       "      <td>2008-08-27</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Headrow</td>\n",
       "      <td>2008-08-27 01:00:00</td>\n",
       "      <td>2008-08-27</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headrow</td>\n",
       "      <td>2008-08-27 02:00:00</td>\n",
       "      <td>2008-08-27</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Headrow</td>\n",
       "      <td>2008-08-27 03:00:00</td>\n",
       "      <td>2008-08-27</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Headrow</td>\n",
       "      <td>2008-08-27 04:00:00</td>\n",
       "      <td>2008-08-27</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FootfallLocation           Timestamp       Date      Hour  TotalFootfall\n",
       "0          Headrow 2008-08-27 00:00:00 2008-08-27  00:00:00           19.0\n",
       "1          Headrow 2008-08-27 01:00:00 2008-08-27  01:00:00           15.0\n",
       "2          Headrow 2008-08-27 02:00:00 2008-08-27  02:00:00           14.0\n",
       "3          Headrow 2008-08-27 03:00:00 2008-08-27  03:00:00           10.0\n",
       "4          Headrow 2008-08-27 04:00:00 2008-08-27  04:00:00            2.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_footfall_column(df, filename):\n",
    "    prefered_source_columns = [\n",
    "        'ReportCount',\n",
    "        'TotalCount',\n",
    "        'InCount',\n",
    "        'Count'\n",
    "    ]\n",
    "    \n",
    "    for source in prefered_source_columns:\n",
    "        if source in list(df.columns):\n",
    "            df['TotalFootfall'] = df[source]\n",
    "            return df\n",
    "        \n",
    "    print(f'No footfall column found in {filename}')\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_location_column(df, filename):\n",
    "    prefered_source_columns = [\n",
    "        'LocationName',\n",
    "        'Location'\n",
    "    ]\n",
    "    \n",
    "    for source in prefered_source_columns:\n",
    "        if source in list(df.columns):\n",
    "            df['FootfallLocation'] = df[source]\n",
    "            return df\n",
    "        \n",
    "    print(f'No location column found in {filename}')\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_hours(x):\n",
    "    x = str(x)\n",
    "    return re.search(r\"^([0-9]{1,2})(?:\\.|\\:|$)\", x).group(1).rjust(2,'0') + ':00:00'\n",
    "\n",
    "    \n",
    "    \n",
    "dataframes_list = []\n",
    "dropped_rows = 0\n",
    "for filename in file_list:\n",
    "    # Ignore the adhoc analysis file\n",
    "    if filename == 'Christmas analysis.csv':\n",
    "        continue\n",
    "        \n",
    "    df_file = pd.read_csv(f'{local_storage}{filename}')\n",
    "    \n",
    "    # Remove any unnamed columns\n",
    "    df_file.drop(df_file.columns[df_file.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "    \n",
    "    # Get the location column\n",
    "    df_file = get_location_column(df_file, filename)\n",
    "    \n",
    "    # Get the footfall column\n",
    "    df_file = get_footfall_column(df_file, filename)\n",
    "    \n",
    "    # Drop any rows where hour is NA\n",
    "    missing_hours = df_file['Hour'].isna().sum()\n",
    "    if missing_hours > 0:\n",
    "        print(f'Warning! {missing_hours} hour values missing in {filename}.')\n",
    "        dropped_rows += missing_hours\n",
    "        df_file = df_file.dropna(subset=['Hour'])\n",
    "    \n",
    "    # Resolve the hour value\n",
    "    df_file['Hour'] = df_file['Hour'].apply(clean_hours)\n",
    "    \n",
    "    # Convert the datetime formats\n",
    "    df_file['Date'] = pd.to_datetime(df_file['Date'], infer_datetime_format=True)\n",
    "    df_file['Timestamp'] = df_file['Date'].dt.strftime('%d/%m/%Y') + ' ' + df_file['Hour']\n",
    "    df_file['Timestamp'] = pd.to_datetime(df_file['Timestamp'], format='%d/%m/%Y %H:%M:%S')\n",
    "    \n",
    "    # Drop columns we don't need\n",
    "    df_file = df_file[['FootfallLocation','Timestamp','Date','Hour','TotalFootfall']]\n",
    "    \n",
    "    dataframes_list.append(df_file)\n",
    "\n",
    "df_output = pd.concat(dataframes_list)\n",
    "\n",
    "# Check and drop duplicates\n",
    "total_duplicates = len(df_output) - len(df_output.drop_duplicates())\n",
    "df_output = df_output.drop_duplicates()\n",
    "\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks\n",
    "The total number of rows plus those dropped for the cleaned dataset above should match our total number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total rows for the cleaned dataset is: 926374\n",
      "The total rows for the cleaned dataset plus dropped rows is: 935814\n",
      "The total rows for the uncleaned dataset is: 935814\n"
     ]
    }
   ],
   "source": [
    "total_uncleaned = df_summary['rows'].sum()\n",
    "total_cleaned = len(df_output)\n",
    "print(f'The total rows for the cleaned dataset is: {total_cleaned}')\n",
    "print(f'The total rows for the cleaned dataset plus dropped rows is: {total_cleaned + dropped_rows + total_duplicates}')\n",
    "print(f'The total rows for the uncleaned dataset is: {total_uncleaned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of missing values is: 0\n"
     ]
    }
   ],
   "source": [
    "print('The total number of missing values is: ' + str(df_output.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total duplicate rows is: 0\n"
     ]
    }
   ],
   "source": [
    "total_duplicates = len(df_output) - len(df_output.drop_duplicates())\n",
    "print(f'The total duplicate rows is: {total_duplicates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just going to quickly do a sense-check of the output dataframe by hour to make sure the values make sense. For example, if a particular hour seems uncharacteristically high (maybe if 3am were higher than 8am), then this would indicate issues with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hour\n",
       "00:00:00     129.508925\n",
       "01:00:00      99.185984\n",
       "02:00:00      84.678965\n",
       "03:00:00      74.193263\n",
       "04:00:00      51.113478\n",
       "05:00:00      53.087274\n",
       "06:00:00     101.591585\n",
       "07:00:00     244.334801\n",
       "08:00:00     544.361027\n",
       "09:00:00     675.986373\n",
       "10:00:00    1081.051449\n",
       "11:00:00    1709.967772\n",
       "12:00:00    2703.506075\n",
       "13:00:00    2932.417243\n",
       "14:00:00    2481.525427\n",
       "15:00:00    2274.299552\n",
       "16:00:00    2023.778633\n",
       "17:00:00    1593.617238\n",
       "18:00:00     909.046009\n",
       "19:00:00     526.381839\n",
       "20:00:00     347.604337\n",
       "21:00:00     260.530712\n",
       "22:00:00     244.033136\n",
       "23:00:00     185.435434\n",
       "Name: TotalFootfall, dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.groupby('Hour')['TotalFootfall'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values here look fine. There is a clear progression of foot traffic over a 24 hour period, building up from 7am onwards and tailing off after 5pm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
